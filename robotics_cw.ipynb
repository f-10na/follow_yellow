{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CAPTURE FROM CAMERA\n",
    "\n",
    "• CREATE CAMERA CLASS.   \n",
    "• INITIALISE SETUP.    \n",
    "• CREATE CAPTURE FUNCTION.    \n",
    "• SAVE VIDEO CAPTURED.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository root found at: /Users/f.kissi/Documents/github_projects/cw\n",
      "['25COC001-Coursework.docx', '.DS_Store', 'requirements.txt', 'motors.py', '__pycache__', 'README.md', '.gitignore', '.venv', 'depth_files', '.git', 'colour_files', 'robotics_cw.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- FIND GIT REPOSITORY ROOT ---\n",
    "def find_repo_root():\n",
    "    path = Path.cwd().resolve()\n",
    "    \n",
    "    for parent in [path] + list(path.parents):\n",
    "        if (parent / \".git\").exists():\n",
    "            return parent\n",
    "    \n",
    "    raise RuntimeError(\"Git repository root not found\")\n",
    "\n",
    "\n",
    "REPO_ROOT = find_repo_root()\n",
    "print(f\"Repository root found at: {REPO_ROOT}\")\n",
    "\n",
    "# Optional: list files in repo root\n",
    "print(os.listdir(REPO_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot is ready:)\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "import motors\n",
    "\n",
    "robot = motors.MotorsYukon(mecanum=False)\n",
    "print(\"Robot is ready:)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyzed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyzed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msl\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyzed'"
     ]
    }
   ],
   "source": [
    "import traitlets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyzed.sl as sl\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import threading\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "# Define a Camera class that inherits from SingletonConfigurable\n",
    "class Camera(SingletonConfigurable):\n",
    "    color_value = traitlets.Any() # monitor the color_value variable\n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "\n",
    "        self.zed = sl.Camera()\n",
    "        # Create a InitParameters object and set configuration parameters\n",
    "        init_params = sl.InitParameters()\n",
    "        init_params.camera_resolution = sl.RESOLUTION.VGA #VGA(672*376), HD720(1280*720), HD1080 (1920*1080) or ...\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA  # Use ULTRA depth mode\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER  # Use meter units (for depth measurements)\n",
    "\n",
    "        # Open the camera\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS: #Ensure the camera has opened succesfully\n",
    "            print(\"Camera Open : \"+repr(status)+\". Exit program.\")\n",
    "            self.zed.close()\n",
    "            exit(1)\n",
    "\n",
    "         # Create and set RuntimeParameters after opening the camera\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "\n",
    "        # Get the height and width\n",
    "        camera_info = self.zed.get_camera_information()\n",
    "        self.width = camera_info.camera_configuration.resolution.width\n",
    "        self.height = camera_info.camera_configuration.resolution.height\n",
    "        self.image = sl.Mat(self.width,self.height,sl.MAT_TYPE.U8_C4, sl.MEM.CPU)\n",
    "        self.depth = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C1, sl.MEM.CPU)\n",
    "        self.point_cloud = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C4, sl.MEM.CPU)\n",
    "\n",
    "        #setup output files\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        self.color_writer = cv2.VideoWriter(f'color_video{timestamp}.avi', fourcc, 30, (672, 376))\n",
    "        self.depth_file   = open(f'depth_video_{timestamp}.bin', 'wb') \n",
    "\n",
    "    def _capture_frames(self): #For data capturing only\n",
    "\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                \n",
    "                # Retrieve Left image\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                # Retrieve depth map. Depth is aligned on the left image\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "    \n",
    "                self.color_value = self.image.get_data()\n",
    "                self.color_value= cv2.cvtColor(self.color_value, cv2.COLOR_BGRA2BGR)\n",
    "                self.depth_image = np.asanyarray(self.depth.get_data())\n",
    "\n",
    "                 # Save to files\n",
    "                try:\n",
    "                    self.color_writer.write(self.color_value)       # write BGR frame to AVI\n",
    "                    self.depth_file.write(self.depth_image.tobytes()) # write raw depth to BIN\n",
    "                except:\n",
    "                    print(\"Error writing files\")\n",
    "                    \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.color_writer.release()\n",
    "            self.depth_file.close()\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "    \n",
    "#create a camera object\n",
    "camera = Camera()\n",
    "camera.start() # start capturing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8662b8a8364f439a37021db3f36afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Drive:', placeholder='w/a/s/d')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_input = widgets.Text(value='', placeholder='w/a/s/d', description='Drive:')\n",
    "\n",
    "def on_text_change(change):\n",
    "    cmd = change['new'][-1] if change['new'] else ''\n",
    "    if   cmd == 'w': robot.forward(0.4)\n",
    "    elif cmd == 's': robot.backward(0.4)\n",
    "    elif cmd == 'a': robot.right(0.4)\n",
    "    elif cmd == 'd': robot.left(0.4)\n",
    "    else:            \n",
    "        robot.stop()\n",
    "\n",
    "text_input.observe(on_text_change, names='value')\n",
    "display(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def read_image_files(colour_file, depth_file):\n",
    "    cap = cv2.VideoCapture(colour_file)\n",
    "    depth_file = open(depth_file, 'rb')\n",
    "    colour_frames = []\n",
    "    depth_frames = []\n",
    "    while True:\n",
    "        ret, colour_frame = cap.read()\n",
    "        depth_data = depth_file.read(672 * 376 * 4)  # F32_C1 means 4 bytes per pixel\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        depth_frame = np.frombuffer(depth_data, dtype=np.float32).reshape((672, 376))\n",
    "\n",
    "        #process the frames as needed\n",
    "        colour_frames.append(colour_frame)\n",
    "        depth_frames.append(depth_frame)\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Read {len(colour_frames)} color frames from {colour_file}\")\n",
    "    print(f\"Read {len(depth_frames)} depth frames from {depth_file.name}\")\n",
    "    return colour_frames, depth_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2170 color frames from /Users/f.kissi/Documents/github_projects/cw/colour_files/color_video20260226_125100.avi\n",
      "Read 2170 depth frames from /Users/f.kissi/Documents/github_projects/cw/depth_files/depth_video_20260226_125100.bin\n",
      "Read 108 color frames from /Users/f.kissi/Documents/github_projects/cw/colour_files/color_video20260226_125325.avi\n",
      "Read 108 depth frames from /Users/f.kissi/Documents/github_projects/cw/depth_files/depth_video_20260226_125325.bin\n",
      "Read 2071 color frames from /Users/f.kissi/Documents/github_projects/cw/colour_files/color_video20260226_125346.avi\n",
      "Read 2071 depth frames from /Users/f.kissi/Documents/github_projects/cw/depth_files/depth_video_20260226_125346.bin\n"
     ]
    }
   ],
   "source": [
    "colour_dir = REPO_ROOT / 'colour_files'\n",
    "depth_dir  = REPO_ROOT / 'depth_files'\n",
    "\n",
    "colour_files = sorted([f for f in os.listdir(colour_dir) if f.endswith('.avi')])\n",
    "depth_files  = sorted([f for f in os.listdir(depth_dir)  if f.endswith('.bin')])\n",
    "\n",
    "for colour_file, depth_file in zip(colour_files, depth_files):\n",
    "    colour_path = colour_dir / colour_file\n",
    "    depth_path  = depth_dir  / depth_file\n",
    "    \n",
    "    colour_frames, depth_frames = read_image_files(str(colour_path), str(depth_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 26,  18,  74],\n",
       "        [ 18,  10,  66],\n",
       "        [ 13,   6,  59],\n",
       "        ...,\n",
       "        [138, 139, 137],\n",
       "        [140, 141, 139],\n",
       "        [143, 144, 141]],\n",
       "\n",
       "       [[ 28,  20,  76],\n",
       "        [ 19,  11,  67],\n",
       "        [ 13,   6,  59],\n",
       "        ...,\n",
       "        [140, 141, 139],\n",
       "        [143, 144, 141],\n",
       "        [145, 146, 144]],\n",
       "\n",
       "       [[ 33,  25,  81],\n",
       "        [ 23,  15,  70],\n",
       "        [ 16,   8,  63],\n",
       "        ...,\n",
       "        [144, 145, 143],\n",
       "        [146, 147, 145],\n",
       "        [147, 148, 146]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 82,  84,  83],\n",
       "        [ 82,  84,  83],\n",
       "        [ 82,  84,  83],\n",
       "        ...,\n",
       "        [ 77,  81,  77],\n",
       "        [ 77,  81,  77],\n",
       "        [ 77,  81,  77]],\n",
       "\n",
       "       [[ 81,  83,  82],\n",
       "        [ 81,  83,  82],\n",
       "        [ 81,  83,  82],\n",
       "        ...,\n",
       "        [ 77,  81,  77],\n",
       "        [ 77,  81,  77],\n",
       "        [ 77,  81,  77]],\n",
       "\n",
       "       [[ 80,  82,  81],\n",
       "        [ 80,  82,  81],\n",
       "        [ 80,  82,  81],\n",
       "        ...,\n",
       "        [ 77,  81,  77],\n",
       "        [ 77,  81,  77],\n",
       "        [ 77,  81,  77]]], shape=(376, 672, 3), dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colour_frames[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan,        nan,        nan, ...,  8116.3022,  7966.288 ,\n",
       "         7944.157 ],\n",
       "       [ 7811.368 ,  7815.382 ,  7895.6675, ...,  5263.9355,  5161.666 ,\n",
       "         5231.499 ],\n",
       "       [ 5068.5645,  5073.4336,  5211.1025, ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [ 5387.046 ,  5392.939 ,  5356.8726, ..., 19860.441 , 19860.441 ,\n",
       "        15524.028 ],\n",
       "       [19035.754 , 19862.121 , 19862.17  , ...,        nan, 11916.133 ,\n",
       "        11916.132 ],\n",
       "       [11916.133 ,  8997.882 ,  8511.523 , ..., 19861.879 , 19861.879 ,\n",
       "        19861.879 ]], shape=(672, 376), dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n"
     ]
    }
   ],
   "source": [
    "print(depth_frames[0].min(), depth_frames[0].max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
