{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CAPTURE FROM CAMERA\n",
    "\n",
    "• CREATE CAMERA CLASS.   \n",
    "• INITIALISE SETUP.    \n",
    "• CREATE CAPTURE FUNCTION.    \n",
    "• SAVE VIDEO CAPTURED.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tutorial 4-20260226', '25COC001-Coursework.docx', '.DS_Store', 'Tutorial 1_Answer_keyboard_control.ipynb', 'motors.py', 'pixel.png', '__pycache__', 'Tutorial 3 Part B Collision Avoidance.ipynb', 'Tutorial 3 Part A Data Recording.ipynb', 'robotics_http.txt', 'lab 2.txt', 'depth_files', 'colour_files', 'robotics_cw.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "ROBOTICS_DIR = Path('/Users/f.kissi/Library/CloudStorage/OneDrive-LoughboroughUniversity/robotics') \n",
    "\n",
    "print(os.listdir(ROBOTICS_DIR))  # confirm files are visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot is ready:)\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "import motors\n",
    "\n",
    "robot = motors.MotorsYukon(mecanum=False)\n",
    "print(\"Robot is ready:)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtraitlets\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyzed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msl\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import traitlets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyzed.sl as sl\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import threading\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "# Define a Camera class that inherits from SingletonConfigurable\n",
    "class Camera(SingletonConfigurable):\n",
    "    color_value = traitlets.Any() # monitor the color_value variable\n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "\n",
    "        self.zed = sl.Camera()\n",
    "        # Create a InitParameters object and set configuration parameters\n",
    "        init_params = sl.InitParameters()\n",
    "        init_params.camera_resolution = sl.RESOLUTION.VGA #VGA(672*376), HD720(1280*720), HD1080 (1920*1080) or ...\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA  # Use ULTRA depth mode\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER  # Use meter units (for depth measurements)\n",
    "\n",
    "        # Open the camera\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS: #Ensure the camera has opened succesfully\n",
    "            print(\"Camera Open : \"+repr(status)+\". Exit program.\")\n",
    "            self.zed.close()\n",
    "            exit(1)\n",
    "\n",
    "         # Create and set RuntimeParameters after opening the camera\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "\n",
    "        # Get the height and width\n",
    "        camera_info = self.zed.get_camera_information()\n",
    "        self.width = camera_info.camera_configuration.resolution.width\n",
    "        self.height = camera_info.camera_configuration.resolution.height\n",
    "        self.image = sl.Mat(self.width,self.height,sl.MAT_TYPE.U8_C4, sl.MEM.CPU)\n",
    "        self.depth = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C1, sl.MEM.CPU)\n",
    "        self.point_cloud = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C4, sl.MEM.CPU)\n",
    "\n",
    "        #setup output files\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        self.color_writer = cv2.VideoWriter(f'color_video{timestamp}.avi', fourcc, 30, (672, 376))\n",
    "        self.depth_file   = open(f'depth_video_{timestamp}.bin', 'wb') \n",
    "\n",
    "    def _capture_frames(self): #For data capturing only\n",
    "\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                \n",
    "                # Retrieve Left image\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                # Retrieve depth map. Depth is aligned on the left image\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "    \n",
    "                self.color_value = self.image.get_data()\n",
    "                self.color_value= cv2.cvtColor(self.color_value, cv2.COLOR_BGRA2BGR)\n",
    "                self.depth_image = np.asanyarray(self.depth.get_data())\n",
    "\n",
    "                 # Save to files\n",
    "                try:\n",
    "                    self.color_writer.write(self.color_value)       # write BGR frame to AVI\n",
    "                    self.depth_file.write(self.depth_image.tobytes()) # write raw depth to BIN\n",
    "                except:\n",
    "                    print(\"Error writing files\")\n",
    "                    \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.color_writer.release()\n",
    "            self.depth_file.close()\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "    \n",
    "#create a camera object\n",
    "camera = Camera()\n",
    "camera.start() # start capturing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8662b8a8364f439a37021db3f36afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Drive:', placeholder='w/a/s/d')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_input = widgets.Text(value='', placeholder='w/a/s/d', description='Drive:')\n",
    "\n",
    "def on_text_change(change):\n",
    "    cmd = change['new'][-1] if change['new'] else ''\n",
    "    if   cmd == 'w': robot.forward(0.4)\n",
    "    elif cmd == 's': robot.backward(0.4)\n",
    "    elif cmd == 'a': robot.right(0.4)\n",
    "    elif cmd == 'd': robot.left(0.4)\n",
    "    else:            \n",
    "        robot.stop()\n",
    "\n",
    "text_input.observe(on_text_change, names='value')\n",
    "display(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_files(colour_file, depth_file):\n",
    "    cap = cv2.VideoCapture(colour_file)\n",
    "    depth_file = open(depth_file, 'rb')\n",
    "    colour_frames = []\n",
    "    depth_frames = []\n",
    "    while True:\n",
    "        ret, colour_frame = cap.read()\n",
    "        depth_data = depth_file.read(672 * 376 * 4)  # F32_C1 means 4 bytes per pixel\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        depth_frame = np.frombuffer(depth_data, dtype=np.float32).reshape((672, 376))\n",
    "\n",
    "        #process the frames as needed\n",
    "        colour_frames.append(colour_frame)\n",
    "        depth_frames.append(depth_frame)\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Read {len(colour_frames)} color frames from {colour_file}\")\n",
    "    print(f\"Read {len(depth_frames)} depth frames from {depth_file.name}\")\n",
    "    return colour_frames, depth_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/f.kissi/Library/CloudStorage/OneDrive-LoughboroughUniversity/robotics/colour_files/color_video20260226_125100.avi\n",
      "Paired with: /Users/f.kissi/Library/CloudStorage/OneDrive-LoughboroughUniversity/robotics/depth_files/depth_video20260226_125100.bin\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLoading: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolour_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPaired with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepth_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mread_image_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolour_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdepth_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mread_image_files\u001b[39m\u001b[34m(colour_file, depth_file)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_image_files\u001b[39m(colour_file, depth_file):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     cap = \u001b[43mcv2\u001b[49m.VideoCapture(colour_file)\n\u001b[32m      3\u001b[39m     depth_file = \u001b[38;5;28mopen\u001b[39m(depth_file, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m     colour_frames = []\n",
      "\u001b[31mNameError\u001b[39m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "colour_dir = ROBOTICS_DIR / 'colour_files'\n",
    "depth_dir  = ROBOTICS_DIR / 'depth_files'\n",
    "\n",
    "for file in os.listdir(colour_dir):\n",
    "    if file.endswith('.avi'):\n",
    "        # match the depth file by replacing .avi with .bin\n",
    "        colour_path = colour_dir / file\n",
    "        depth_path  = depth_dir / file.replace('color_', 'depth_').replace('.avi', '.bin')\n",
    "        \n",
    "        print(f'Loading: {colour_path}')\n",
    "        print(f'Paired with: {depth_path}')\n",
    "        \n",
    "        read_image_files(str(colour_path), str(depth_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
